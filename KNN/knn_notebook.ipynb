{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabcdf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e098bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):\n",
    "    u = np.diagonal((x @ x.T)).reshape(x.shape[0], 1)   # квадраты векторов из матрицы x\n",
    "    v = np.diagonal(y @ y.T).reshape(1, y.shape[0])     # квадраты векторов из матрицы y\n",
    "    u = u @ np.ones(y.shape[0]).reshape(1, y.shape[0])  # приводим к нужной размерности, так как на выходе должна быть матрица попарных расстояний \n",
    "    v = np.ones(x.shape[0]).reshape(x.shape[0], 1) @ v  # приводим к нужной размерности, так как на выходе должна быть матрица попарных расстояний \n",
    "    return np.sqrt(u + v - 2*(x @ y.T))                 # вычитаем попарные скалярные произведения векторов из x и векторов из y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "73408960",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,0,1],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "630cc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[1,1,1], [1,2,3], [4,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e13e18ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 2.82842712, 3.        ],\n",
       "       [1.41421356, 3.        , 4.        ]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(np.array([[1,0,1],[0,0,1]]), np.array([[1,1,1], [1,2,3], [4,0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42da1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(x, y): # 1- cos(x,y); cos(x,y) = (x,y)/|x||y|\n",
    "    u = np.sqrt(np.diagonal((x @ x.T)).reshape(x.shape[0], 1))  # длины векторов из матрицы x\n",
    "    v = np.sqrt(np.diagonal(y @ y.T).reshape(1, y.shape[0]))    # длины векторов из матрицы y\n",
    "    u = u @ np.ones(y.shape[0]).reshape(1, y.shape[0])  # приводим к нужной размерности, так как на выходе должна быть матрица попарных расстояний \n",
    "    v = np.ones(x.shape[0]).reshape(x.shape[0], 1) @ v  # приводим к нужной размерности, так как на выходе должна быть матрица попарных расстояний \n",
    "    return 1 - x @ y.T / u /v                           # делим скалярные произведения векторов их на длины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "dd34b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,0,1],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9253033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[1,1,1], [1,2,3], [4,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8175846b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18350342, 0.24407105, 0.14250707],\n",
       "       [0.42264973, 0.19821627, 0.75746437]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_distance(np.array([[1,0,1],[0,0,1]]), np.array([[1,1,1], [1,2,3], [4,0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb90ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighborsFinder:\n",
    "    def __init__(self, n_neighbors, metric=\"euclidean\"):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "        if metric == \"euclidean\":\n",
    "            self._metric_func = euclidean_distance\n",
    "        elif metric == \"cosine\":\n",
    "            self._metric_func = cosine_distance\n",
    "        else:\n",
    "            raise ValueError(\"Metric is not supported\", metric)\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._X = X\n",
    "        return self\n",
    "\n",
    "    def kneighbors(self, X, return_distance=False):  # X - объекты тестовой выборки\n",
    "        # Сначала считаем расстояния от тестовой выборки до обучающей\n",
    "        Dist = self._metric_func(X, self._X)\n",
    "        # обрабатываем случай, когда число соседей = n_neighbors, сортируем и выводим всё\n",
    "        if self.n_neighbors == Dist.shape[1]: \n",
    "            indices = Dist.argsort(axis=1)\n",
    "            distances = np.take_along_axis(Dist, indices, axis=1)\n",
    "            if return_distance:\n",
    "                return distances, indices\n",
    "            else:\n",
    "                return indices\n",
    "        else:\n",
    "            # находим индексы n_neighbors лучших в каждой строке, то есть ближайших соседей \n",
    "            indices = np.argpartition(Dist, self.n_neighbors, axis=1)[:, :self.n_neighbors] \n",
    "            ranks_top = np.take_along_axis(Dist, indices, axis=1)  # выбираем этих лучших\n",
    "            # np.argpartition возвращает неотсортриованный список лучших, поэтому сортируем его\n",
    "            indices_top = ranks_top.argsort(axis=1)                                   \n",
    "            indices = np.take_along_axis(indices, indices_top, axis=1)   # получаем индексы отсортрованных ближайших соседей\n",
    "            distances = np.take_along_axis(Dist, indices, axis=1)  # получаем расстояния до ближайших соседей\n",
    "            if return_distance:\n",
    "                return distances, indices\n",
    "            else:\n",
    "                return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c037d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.RandomState(9872)\n",
    "X = seed.permutation(25).reshape(5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93401431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NearestNeighborsFinder at 0x19d2755e8b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighborsFinder(n_neighbors=1, metric='euclidean')\n",
    "nn.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd52d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nn.kneighbors(X, return_distance=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b07864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    EPS = 1e-5\n",
    "\n",
    "    def __init__(self, n_neighbors, algorithm='my_own', metric='euclidean', weights='uniform'):\n",
    "        if algorithm == 'my_own':\n",
    "            finder = NearestNeighborsFinder(n_neighbors=n_neighbors, metric=metric)\n",
    "        elif algorithm in ('brute', 'ball_tree', 'kd_tree',):\n",
    "            finder = NearestNeighbors(n_neighbors=n_neighbors, algorithm=algorithm, metric=metric)\n",
    "        else:\n",
    "            raise ValueError(\"Algorithm is not supported\", metric)\n",
    "\n",
    "        if weights not in ('uniform', 'distance'):\n",
    "            raise ValueError(\"Weighted algorithm is not supported\", weights)\n",
    "\n",
    "        self._finder = finder\n",
    "        self._weights = weights\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._finder.fit(X)\n",
    "        self._labels = np.asarray(y)\n",
    "        return self\n",
    "\n",
    "    def _predict_precomputed(self, indices, distances):  \n",
    "        # найдём метки соседей\n",
    "        kneighbors_labels = np.take_along_axis(self._labels.reshape(-1, 1), indices.T, axis=0)\n",
    "        if self._weights == 'distance':\n",
    "            weights = 1 / (distances + self.EPS)  # веса обратно пропорциальны расстояниям до соседей\n",
    "            # сделаем из меток сосдей 3d-array, взял пример преобразования со stackoverflow\n",
    "            kneighbors_labels_3D = kneighbors_labels.T[:,:, np.newaxis]\n",
    "            weighrs_3d = weights[:, :, np.newaxis]  # аналогично поступим с весами\n",
    "            # размножим метки соседей по матрицам: по строкам соседи, по столбцам возможные метки,\n",
    "            # а третья размерность - элементы тестовой выборки\n",
    "            # сделали это, чтобы можно было по отдельности посчитать взвешенную сумму для каждого возможного лейбла \n",
    "            mask = kneighbors_labels_3D == np.arange(self._labels.max() + 1)\n",
    "            # заполним эту маску весами, для этого умножим её на веса\n",
    "            weighted_mask = weighrs_3d * mask\n",
    "            # посчитаем требуемую сумму по столбцам(3d-array, поэтому тут axis=1, то есть вдоль второй оси)\n",
    "            res = np.sum(weighted_mask, axis=1)\n",
    "            return np.argmax(res, axis=1) # выберем индексы меток с максимальной суммой по строчкам\n",
    "        else:\n",
    "            def find_label(a):\n",
    "                return np.argmax(np.bincount(a))\n",
    "            return np.apply_along_axis(find_label, 0, kneighbors_labels)  # выберем самые часто встречаемые метки\n",
    "            \n",
    "    def kneighbors(self, X, return_distance=False):\n",
    "        return self._finder.kneighbors(X, return_distance=return_distance)\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances, indices = self.kneighbors(X, return_distance=True)\n",
    "        return self._predict_precomputed(indices, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9afdbd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.RandomState(9872)\n",
    "X_train = seed.permutation(25).reshape(5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f68c7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.KNNClassifier at 0x19d27573190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = KNNClassifier(n_neighbors=3)\n",
    "nn.fit(X_train, y = np.array([1,2,2,1,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db29bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.RandomState(123)\n",
    "X_test = seed.permutation(20).reshape(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b794e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nn.kneighbors(X_test, return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61799231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn._predict_precomputed(indices, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca4ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchedKNNClassifier(KNNClassifier):\n",
    "    '''\n",
    "    Нам нужен этот класс, потому что мы хотим поддержку обработки батчами\n",
    "    в том числе для классов поиска соседей из sklearn\n",
    "    '''\n",
    "\n",
    "    def __init__(self, n_neighbors, algorithm='my_own', metric='euclidean', weights='uniform', batch_size=None):\n",
    "        KNNClassifier.__init__(\n",
    "            self,\n",
    "            n_neighbors=n_neighbors,\n",
    "            algorithm=algorithm,\n",
    "            weights=weights,\n",
    "            metric=metric,\n",
    "        )\n",
    "        self._batch_size = batch_size\n",
    "\n",
    "    def kneighbors(self, X, return_distance=False):\n",
    "        if self._batch_size is None or self._batch_size >= X.shape[0]:\n",
    "            return super().kneighbors(X, return_distance=return_distance)\n",
    "            # super() - доступ к классу-наследнику, который не разбивает на батчи\n",
    "        else:\n",
    "            import math as m\n",
    "            number_of_steps = m.ceil(X.shape[0] / self._batch_size)\n",
    "            if return_distance:\n",
    "                # создаём два списка, в которые будем складывать индексы и расстояния для каждого куска\n",
    "                batched_ind = list(np.zeros(number_of_steps, int))\n",
    "                batched_dist = list(np.zeros(number_of_steps))\n",
    "                for i in range(number_of_steps):  # выполняем поиск ближающих соседей для каждого батча\n",
    "                    batched_dist[i], batched_ind[i] = super().kneighbors(X[self._batch_size*i:self._batch_size*(i+1), :],\n",
    "                                                                     return_distance=return_distance)\n",
    "                batched_ind = np.vstack(batched_ind)  # собираем результаты вместе\n",
    "                batched_dist = np.vstack(batched_dist)\n",
    "                return batched_dist, batched_ind\n",
    "            else:\n",
    "                return np.vstack([super().kneighbors(X[self._batch_size*i:self._batch_size*(i+1), :],\n",
    "                                                                     return_distance=return_distance) for i in range(number_of_steps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "29cd4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, BaseCrossValidator\n",
    "from sklearn.metrics import accuracy_score\n",
    "def knn_cross_val_score(X, y, k_list, scoring, metric, weights, cv=None, **kwargs):\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    if scoring == \"accuracy\":\n",
    "        scorer = accuracy_score\n",
    "    else:\n",
    "        raise ValueError(\"Unknown scoring metric\", scoring)\n",
    "\n",
    "    if cv is None:\n",
    "        cv = KFold(n_splits=5)\n",
    "    elif not isinstance(cv, BaseCrossValidator):\n",
    "        raise TypeError(\"cv should be BaseCrossValidator instance\", type(cv))\n",
    "\n",
    "    i = 0\n",
    "    scores = {}\n",
    "    k_max = np.max(k_list)\n",
    "    models_KFold = list(np.zeros(cv.get_n_splits()))\n",
    "    distances_KFold = list(np.zeros(cv.get_n_splits()))\n",
    "    indices_KFold = list(np.zeros(cv.get_n_splits()))\n",
    "    score_KFold = list(np.zeros(cv.get_n_splits()))\n",
    "\n",
    "    for train_index, test_index in cv.split(X):  # разбиваем обучающую выборку на фолды\n",
    "        for k in np.sort(k_list)[::-1]:\n",
    "            if k == k_max:\n",
    "                x_train, x_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                models_KFold[i] = BatchedKNNClassifier(n_neighbors=k_max, metric=metric, weights=weights)\n",
    "                models_KFold[i].fit(x_train, y_train)\n",
    "                # считаем расстояния и индексы соседей только для большего k\n",
    "                distances_KFold[i], indices_KFold[i] = models_KFold[i].kneighbors(x_test, return_distance=True)\n",
    "                y_pred = models_KFold[i]._predict_precomputed(indices_KFold[i], distances_KFold[i])\n",
    "                scores[k] = accuracy_score(y_test, y_pred)  # считаем скоры для всех k\n",
    "            else:\n",
    "                # выбираем нужное количество сеседей\n",
    "                y_pred = models_KFold[i]._predict_precomputed(indices_KFold[i][:, :k], distances_KFold[i][:, :k])\n",
    "                scores[k] = accuracy_score(y_test, y_pred)\n",
    "        score_KFold[i] = list(scores.values())\n",
    "        i += 1\n",
    "    score_KFold = np.asarray(score_KFold)\n",
    "    scores = {}\n",
    "    for k in range(len(k_list)):  # преобразуем вывод к нужному виду\n",
    "        scores[str(np.sort(k_list)[::-1][k])] = score_KFold[:, k]\n",
    "    return scores  # возвращаем значения accuracy для каждого k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1304ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
